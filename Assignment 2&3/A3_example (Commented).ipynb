{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQhSr_LqSIg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading the test and training the data\n",
        "!wget -q https://l1nna.com/372/Assignment/A2-3/train.csv\n",
        "!wget -q https://l1nna.com/372/Assignment/A2-3/test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaABvQpluwjs",
        "colab_type": "code",
        "outputId": "53f3a5c5-5348-47b0-dd9f-f7c72f419882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# Reading the csv files into the variables using pandas so they can be used in the notebook\n",
        "#   index_col='id': index column based on id as it is already unique\n",
        "xy_train_df = pd.read_csv('train.csv')\n",
        "x_test_df  = pd.read_csv('test.csv' , index_col='id')\n",
        "\n",
        "# Add a new column 'length' for the training dataset containing the length of the review for each observation\n",
        "xy_train_df['length'] = xy_train_df.apply(lambda x: len(x.review), axis=1)\n",
        "\n",
        "# Sort the observations based on the length \n",
        "xy_train_df = xy_train_df.sort_values('length')\n",
        "xy_train_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6037</th>\n",
              "      <td>2596</td>\n",
              "      <td>1</td>\n",
              "      <td>Five Stars_GOOD</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5353</th>\n",
              "      <td>4643</td>\n",
              "      <td>1</td>\n",
              "      <td>Love it_Love it</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2545</th>\n",
              "      <td>8791</td>\n",
              "      <td>1</td>\n",
              "      <td>Five Stars_Good</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3902</th>\n",
              "      <td>6098</td>\n",
              "      <td>1</td>\n",
              "      <td>Five Stars_love!</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2850</th>\n",
              "      <td>4609</td>\n",
              "      <td>1</td>\n",
              "      <td>love these_so cute!</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5651</th>\n",
              "      <td>518</td>\n",
              "      <td>1</td>\n",
              "      <td>So far, it's awesome_Ok, so I'll say up front ...</td>\n",
              "      <td>5765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1615</th>\n",
              "      <td>124</td>\n",
              "      <td>1</td>\n",
              "      <td>It Works (Read Tips For Potential Effectivenes...</td>\n",
              "      <td>6740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>7257</td>\n",
              "      <td>1</td>\n",
              "      <td>An exquisitely effective product with an astou...</td>\n",
              "      <td>8082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4859</th>\n",
              "      <td>7555</td>\n",
              "      <td>1</td>\n",
              "      <td>Gorgeous professional looking manicure at home...</td>\n",
              "      <td>8134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>4823</td>\n",
              "      <td>1</td>\n",
              "      <td>WAITED TO WRITE THIS REVIEW UNTIL AFTER READIN...</td>\n",
              "      <td>12773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6223 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  rating                                             review  length\n",
              "6037  2596       1                                    Five Stars_GOOD      15\n",
              "5353  4643       1                                    Love it_Love it      15\n",
              "2545  8791       1                                    Five Stars_Good      15\n",
              "3902  6098       1                                   Five Stars_love!      16\n",
              "2850  4609       1                                love these_so cute!      19\n",
              "...    ...     ...                                                ...     ...\n",
              "5651   518       1  So far, it's awesome_Ok, so I'll say up front ...    5765\n",
              "1615   124       1  It Works (Read Tips For Potential Effectivenes...    6740\n",
              "5046  7257       1  An exquisitely effective product with an astou...    8082\n",
              "4859  7555       1  Gorgeous professional looking manicure at home...    8134\n",
              "2758  4823       1  WAITED TO WRITE THIS REVIEW UNTIL AFTER READIN...   12773\n",
              "\n",
              "[6223 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHl0DGCyvA7l",
        "colab_type": "code",
        "outputId": "0ed30273-6421-4f6d-c402-39cfcec30c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "vocab_size = 10000\n",
        "# Maximum number of word in text\n",
        "max_len = 256\n",
        "\n",
        "# Split the original training data (xy_train_df) into 20% of xy_validation (validation set) and 80% of xy_train (training set)\n",
        "xy_train, xy_validation = train_test_split(xy_train_df, test_size=0.2)\n",
        "\n",
        "# build vocabulary from training set\n",
        "#   Tokenizer: based on the data, removes any of the following characters “!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
        "#   fit_on_texts: Updates internal vocabulary based on a list of texts.\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(xy_train.review)\n",
        "\n",
        "# padding is done inside: \n",
        "#   Convert a list of texts (review) to a Numpy matrix with 256 columns with binary values\n",
        "#     mode='binary': Whether the word exists (1) or not (0) in the text. Helps in teaching the model.\n",
        "x_train = tokenizer.texts_to_matrix(xy_train.review, mode='binary')[:, :max_len]\n",
        "y_train = xy_train.rating\n",
        "\n",
        "x_valid = tokenizer.texts_to_matrix(xy_validation.review, mode='binary')[:, :max_len]\n",
        "y_valid = xy_validation.rating\n",
        "\n",
        "x_test = tokenizer.texts_to_matrix(x_test_df.review, mode='binary')[:, :max_len]\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_valid.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 1. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            "(4978, 256)\n",
            "(1245, 256)\n",
            "(2667, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EtEv2RivFKP",
        "colab_type": "code",
        "outputId": "4d804bfd-2e12-43ec-f239-55e322f845f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# model: Sequential model is a linear stack of layers\n",
        "model = keras.Sequential()\n",
        "# Embedding\n",
        "#   Given the number of unqiue words (vocab_size) and size of embedding vector\n",
        "#   Create a table of vector size (10000, 2) with 20 weights for the embedding vector for each unique word\n",
        "model.add(keras.layers.Embedding(vocab_size, 20))\n",
        "\n",
        "\n",
        "### We are adding layers in the model\n",
        "\n",
        "#---- CuDNNGRU works only for tf 1.x ----#\n",
        "#   Parameter=100: 100 dimensionality of the output space\n",
        "#   CuDNNLSTM: Fast LSTM implementation backed by cuDNN\n",
        "#       Shape is (8 * 100) based on the source code on GitHub\n",
        "model.add(tf.compat.v1.keras.layers.CuDNNLSTM(100))\n",
        "\n",
        "# Fully connected layers are defined using Dense\n",
        "# Output layer has one node and uses the sigmoid activation function\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "## For the model\n",
        "# Using loss function of binary_crossentropy to evaluate a set of weights\n",
        "# Optimizer Adam is used to search through different weights for the network\n",
        "# clipnorm=4: All parameter gradients will be clipped to a maximum norm of 4. \n",
        "#             Helps in preventing messing up of parameters due to vanishing/exploding gradients\n",
        "model.compile(\n",
        "    optimizer=Adam(clipnorm=4.),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train on x_train as input and y_train as output\n",
        "# Use validation set to tune the parameter\n",
        "# batch_size is the number of samples per gradient update\n",
        "# 15 epochs to train the model. An epoch is an iteration over the entire x and y data provided.\n",
        "# verbose as 1 to see progress bar\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=15,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(x_valid, y_valid),\n",
        "                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "78/78 [==============================] - 4s 53ms/step - loss: 0.4073 - accuracy: 0.8748 - val_loss: 0.3678 - val_accuracy: 0.8811\n",
            "Epoch 2/15\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3799 - accuracy: 0.8748 - val_loss: 0.3679 - val_accuracy: 0.8811\n",
            "Epoch 3/15\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3776 - accuracy: 0.8748 - val_loss: 0.3685 - val_accuracy: 0.8811\n",
            "Epoch 4/15\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3780 - accuracy: 0.8748 - val_loss: 0.3686 - val_accuracy: 0.8811\n",
            "Epoch 5/15\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3776 - accuracy: 0.8748 - val_loss: 0.3678 - val_accuracy: 0.8811\n",
            "Epoch 6/15\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3775 - accuracy: 0.8748 - val_loss: 0.3713 - val_accuracy: 0.8811\n",
            "Epoch 7/15\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3780 - accuracy: 0.8748 - val_loss: 0.3730 - val_accuracy: 0.8811\n",
            "Epoch 8/15\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3785 - accuracy: 0.8748 - val_loss: 0.3718 - val_accuracy: 0.8811\n",
            "Epoch 9/15\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3787 - accuracy: 0.8748 - val_loss: 0.3682 - val_accuracy: 0.8811\n",
            "Epoch 10/15\n",
            "78/78 [==============================] - 4s 47ms/step - loss: 0.3774 - accuracy: 0.8748 - val_loss: 0.3721 - val_accuracy: 0.8811\n",
            "Epoch 11/15\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3782 - accuracy: 0.8748 - val_loss: 0.3682 - val_accuracy: 0.8811\n",
            "Epoch 12/15\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.3775 - accuracy: 0.8748 - val_loss: 0.3678 - val_accuracy: 0.8811\n",
            "Epoch 13/15\n",
            "78/78 [==============================] - 4s 45ms/step - loss: 0.3764 - accuracy: 0.8748 - val_loss: 0.3689 - val_accuracy: 0.8811\n",
            "Epoch 14/15\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3782 - accuracy: 0.8748 - val_loss: 0.3683 - val_accuracy: 0.8811\n",
            "Epoch 15/15\n",
            "78/78 [==============================] - 4s 46ms/step - loss: 0.3776 - accuracy: 0.8748 - val_loss: 0.3717 - val_accuracy: 0.8811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_naN0rn3OlN",
        "colab_type": "code",
        "outputId": "98728876-1d99-486f-ac81-c95b2368b2ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Evaluate the model based on validation set.\n",
        "model.evaluate(x_valid, y_valid)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "39/39 [==============================] - 1s 18ms/step - loss: 0.3693 - accuracy: 0.8811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3693195879459381, 0.8811244964599609]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byj-weFZvaaS",
        "colab_type": "code",
        "outputId": "53f25de8-2f4a-4d71-879e-e8c601891662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_predict = np.squeeze(model.predict_classes(x_valid),  axis=-1)\n",
        "\n",
        "from sklearn.metrics import  f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(f1_score(y_valid, y_predict, average='micro'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8811244979919679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FDSaQaxvG0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run on testing set:\n",
        "y_predict = np.squeeze(model.predict_classes(x_test), axis=-1)\n",
        "\n",
        "# Convert output by adding the predicted id and rating for the test and add to file for sample_submission.csv\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.index,\n",
        "     'rating':y_predict}).to_csv('sample_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}